# -*- coding: utf-8 -*-
"""cvdl_hw2_q5.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vdPQGsPvOxuG5G6CKezX8rqbEdqyDoie

# download and import
"""

import os

import numpy as np

from PIL import Image, UnidentifiedImageError

import matplotlib.pyplot as plt

import torch
import torchvision
import torchinfo

from sklearn.model_selection import train_test_split

from typing import Any, Optional, Callable

"""# class and define"""

class CustomDataset(torch.utils.data.Dataset):
    img_paths: list[str]
    img_labels: list[float]
    transform: Optional[Callable]
    def __init__(self, img_paths: list[str],
                 img_labels: list[float],
                 transform = None):
        self.img_paths = img_paths
        self.img_labels = img_labels
        self.transform = transform

    def __len__(self):
        return len(self.img_paths)

    def __getitem__(self, idx: int):
        image = Image.open(self.img_paths[idx]).convert('RGB')
        label = torch.tensor(self.img_labels[idx], dtype=torch.float32)
        if self.transform:
            image = self.transform(image)
        #if image.shape[0] == 1:
        #    image = torch.cat((image, image, image), 0)

        return image, label

def split_and_shuffle(cat_dir: str, dog_dir: str):
    paths = []
    labels = []
    for file in os.listdir(cat_dir):
        fileabs = os.path.join(cat_dir, file)
        try:
            Image.open(fileabs).convert('RGB')
            paths.append(fileabs)
            labels.append(1)
        except UnidentifiedImageError:
            print(f"{fileabs} corrupted, ignore it")
    for file in os.listdir(dog_dir):
        fileabs = os.path.join(dog_dir, file)
        try:
            Image.open(fileabs).convert('RGB')
            paths.append(fileabs)
            labels.append(0)
        except UnidentifiedImageError:
            print(f"{fileabs} corrupted, ignore it")
    # train_path, valid_path, train_label, valid_label
    return train_test_split(paths, labels, test_size=0.2, shuffle=True)

def train_loop(dataloader, model, loss_fn, optimizer, device):
    size = len(dataloader.dataset)
    num_batches = len(dataloader)
    batchloss = 0
    batchaccuracy = 0
    totalloss = 0
    totalcorrect = 0

    model.train()
    for batch, (X, Y) in enumerate(dataloader):
        # Compute prediction and loss
        X = X.to(device)
        Y = torch.unsqueeze(Y, 1).to(device)
        pred = model(X)
        loss = loss_fn(pred, Y)
        batchloss += loss.item()
        totalloss += loss.item()
        accuracy = (torch.sign(pred-0.5) == torch.sign(Y-0.5)).type(torch.float).sum().item()
        batchaccuracy += accuracy
        totalcorrect += accuracy
        # Backpropagation
        loss.backward()
        optimizer.step()
        optimizer.zero_grad()

        if batch % 100 == 99:
            batchloss /= 100
            batchaccuracy /= 3200
            current = (batch + 1) * len(X)
            print(f"Accuracy: {(100*batchaccuracy):>0.1f}%, loss: {batchloss:>7f}  [{current:>5d}/{size:>5d}]")
            batchloss = 0
            batchaccuracy = 0

    totalloss /= num_batches
    totalaccuracy = totalcorrect / size

    print(f"Train Error: \n Accuracy: {(100*totalaccuracy):>0.1f}%, Avg loss: {totalloss:>8f} \n")

    return totalloss, totalaccuracy

def test_loop(dataloader, model, loss_fn, device):
    size = len(dataloader.dataset)
    num_batches = len(dataloader)
    test_loss = 0
    correct = 0

    model.eval()


    # Evaluating the model with torch.no_grad() ensures that no gradients are computed during test mode
    # also serves to reduce unnecessary gradient computations and memory usage for tensors with requires_grad=True
    with torch.no_grad():
        for X, Y in dataloader:
            X = X.to(device)
            Y = torch.unsqueeze(Y, 1).to(device)
            pred = model(X)
            test_loss += loss_fn(pred, Y).item()
            # correct += (pred.argmax(1) == Y).type(torch.float).sum().item()
            correct += (torch.sign(pred-0.5) == torch.sign(Y-0.5)).type(torch.float).sum().item()
    test_loss /= num_batches
    accuracy = correct / size

    print(f"Validation Error: \n Accuracy: {(100*accuracy):>0.1f}%, Avg loss: {test_loss:>8f} \n")

    return test_loss, accuracy

"""# hyperparameter, dataloader and model"""

learning_rate = 0.001
batch_size = 32
epochs = 50

device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

train_path, valid_path, train_label, valid_label = split_and_shuffle("PetImages/Cat", "PetImages/Dog")

train_data = CustomDataset(train_path, train_label,
                           transform=torchvision.transforms.Compose([
                                torchvision.transforms.Resize(size=(224, 224)),
                                torchvision.transforms.RandomHorizontalFlip(p=0.5),
                                torchvision.transforms.RandomVerticalFlip(p=0.2),
                                torchvision.transforms.RandomRotation(30),
                                torchvision.transforms.ToTensor(),
                                torchvision.transforms.RandomErasing(p=0.5, scale=(0.02, 0.3)),
                            ]))
valid_data = CustomDataset(valid_path, valid_label, transform=torchvision.transforms.Compose([
                                torchvision.transforms.Resize(size=(224, 224)),
                                torchvision.transforms.ToTensor(),
                            ]))
train_loader = torch.utils.data.DataLoader(train_data, batch_size=32, shuffle=True)
valid_loader = torch.utils.data.DataLoader(valid_data, batch_size=32, shuffle=True)

model = torchvision.models.resnet50()

model.fc = torch.nn.Sequential(torch.nn.Linear(2048, 1),
                               torch.nn.Sigmoid())

model.to(device)
result = torchinfo.summary(model, (32, 3, 224, 224))
print(result)

"""# execute"""

optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)
loss_fn = torch.nn.MSELoss()

model.to(device)

train_loss = []
train_accuracy = []
test_loss = []
test_accuracy = []

for t in range(epochs):
    print(f"Epoch {t+1}\n-------------------------------")
    loss, accuracy = train_loop(train_loader, model, loss_fn, optimizer, device)
    train_loss.append(loss)
    train_accuracy.append(accuracy)
    loss, accuracy = test_loop(valid_loader, model, loss_fn, device)
    test_loss.append(loss)
    test_accuracy.append(accuracy)
    if t % 5 == 4:
      torch.save(model.state_dict(), f"Resnet50_v2_Epoch_{t+1}.pth")

print("Done!")

import pickle
with open("train_loss.p","wb") as f:
    pickle.dump(train_loss, f)
with open("train_accuracy.p","wb") as f:
    pickle.dump(train_accuracy, f)
with open("test_loss.p","wb") as f:
    pickle.dump(test_loss, f)
with open("test_accuracy.p","wb") as f:
    pickle.dump(test_accuracy, f)

actual_epochs = epochs

plt.subplot(2, 1, 1)
plt.ylabel('train / validation loss')
plt.xlabel('epochs')
plt.plot([*range(1, actual_epochs + 1)], train_loss, 'r', [*range(1, actual_epochs + 1)], test_loss, 'b')

plt.subplot(2, 1, 2)
plt.ylabel('train / validation accuracy')
plt.xlabel('epochs')
plt.plot([*range(1, actual_epochs + 1)], train_accuracy, 'r', [*range(1, actual_epochs + 1)], test_accuracy, 'b')

plt.tight_layout()
plt.savefig('resnet50.png')
plt.show()
